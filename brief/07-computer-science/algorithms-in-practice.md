# ‚öôÔ∏è Algorithms in Practice - Microservices Edition

**Category**: Computer Science Foundations  
**Difficulty**: Intermediate to Advanced  
**Focus**: Real algorithms used in your project

---

## üìñ Overview

Algorithms power critical features in microservices. This document explains the algorithms actually implemented in your booking system, with complexity analysis and performance impact.

---

## üîÑ Exponential Backoff (Retry Algorithm)

### Problem

Service calls fail due to transient errors. Retry immediately ‚Üí thundering herd problem.

### Algorithm

```
Retry with increasing delays:
Attempt 1: Wait 2^1 = 2 seconds
Attempt 2: Wait 2^2 = 4 seconds
Attempt 3: Wait 2^3 = 8 seconds
...
Attempt n: Wait 2^n seconds (capped at max)
```

### Implementation in Your Project

**File**: `src/BookingService/Services/BookingServiceImpl.cs`

```csharp
public class RetryPolicy
{
    private const int MaxRetries = 5;
    private const int BaseDelaySeconds = 2;
    private const int MaxDelaySeconds = 60;
    
    public async Task<T> ExecuteWithRetryAsync<T>(
        Func<Task<T>> operation,
        string operationName)
    {
        for (int attempt = 0; attempt <= MaxRetries; attempt++)
        {
            try
            {
                return await operation();
            }
            catch (Exception ex) when (attempt < MaxRetries)
            {
                // Calculate exponential backoff
                var delay = Math.Min(
                    BaseDelaySeconds * Math.Pow(2, attempt),
                    MaxDelaySeconds
                );
                
                _logger.LogWarning(
                    "Attempt {Attempt} failed for {Operation}. " +
                    "Retrying in {Delay}s. Error: {Error}",
                    attempt + 1, operationName, delay, ex.Message
                );
                
                await Task.Delay(TimeSpan.FromSeconds(delay));
            }
        }
        
        throw new MaxRetriesExceededException();
    }
}
```

### With Jitter (Randomization)

```csharp
// Add randomness to prevent synchronized retries
public class ExponentialBackoffWithJitter
{
    private readonly Random _random = new();
    
    public TimeSpan CalculateDelay(int attempt)
    {
        // Base delay: 2^attempt seconds
        var exponentialDelay = Math.Pow(2, attempt);
        
        // Add jitter: ¬±25% randomness
        var jitter = _random.NextDouble() * 0.5 + 0.75; // 0.75 to 1.25
        
        var delay = exponentialDelay * jitter;
        
        return TimeSpan.FromSeconds(Math.Min(delay, 60));
    }
}
```

### Why Jitter Matters

**Without Jitter**:
```
100 services restart simultaneously
All retry at: t=2s, t=4s, t=8s
Result: Thundering herd at exact same moments
```

**With Jitter**:
```
100 services restart simultaneously
Service 1 retries at: t=1.8s, t=3.5s, t=7.2s
Service 2 retries at: t=2.3s, t=4.7s, t=9.1s
...
Result: Retries spread out, load distributed
```

### Performance Analysis

**Scenario**: RabbitMQ down for 10 seconds

| Strategy | Total Wait Time | Success Rate | Load on RabbitMQ |
|----------|----------------|--------------|------------------|
| No retry | 0s | 0% | 0 |
| Fixed 1s retry | 10s | 100% | High (all retry together) |
| Exponential | 2+4=6s | 100% | Medium |
| Exponential + Jitter | 2+4=6s | 100% | Low (spread out) |

**Code Location**: `/docs/phase3-event-integration/RETRY_LOGIC_AND_POLLY.md`

---

## ü™£ Token Bucket (Rate Limiting Algorithm)

### Problem

Protect API from abuse. Need to limit requests per time window.

### Algorithm

```
Bucket capacity: N tokens
Refill rate: R tokens per second

For each request:
1. Check if bucket has ‚â•1 token
2. If yes: Remove 1 token, allow request
3. If no: Reject request (429 Too Many Requests)
4. Continuously refill tokens at rate R
```

### Visual Representation

```
Bucket (Capacity: 10)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óã‚óã      ‚îÇ  8 tokens available
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì Request consumes 1 token
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óã‚óã‚óã      ‚îÇ  7 tokens remaining
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üë Refill: +1 token per second
```

### Implementation in Your Project

**File**: `src/ApiGateway/Middleware/RateLimitingMiddleware.cs`

```csharp
public class TokenBucketRateLimiter
{
    private readonly int _capacity;
    private readonly int _refillRate; // tokens per second
    private int _tokens;
    private DateTime _lastRefill;
    private readonly SemaphoreSlim _lock = new(1, 1);
    
    public TokenBucketRateLimiter(int capacity, int refillRate)
    {
        _capacity = capacity;
        _refillRate = refillRate;
        _tokens = capacity; // Start full
        _lastRefill = DateTime.UtcNow;
    }
    
    public async Task<bool> AllowRequestAsync()
    {
        await _lock.WaitAsync();
        try
        {
            // 1. Calculate tokens to add since last refill
            var now = DateTime.UtcNow;
            var elapsedSeconds = (now - _lastRefill).TotalSeconds;
            var tokensToAdd = (int)(elapsedSeconds * _refillRate);
            
            if (tokensToAdd > 0)
            {
                // 2. Refill bucket (capped at capacity)
                _tokens = Math.Min(_capacity, _tokens + tokensToAdd);
                _lastRefill = now;
            }
            
            // 3. Check if token available
            if (_tokens >= 1)
            {
                _tokens--; // Consume token
                return true;
            }
            
            return false; // Bucket empty
        }
        finally
        {
            _lock.Release();
        }
    }
}
```

### Configuration in Your Project

```json
{
  "RateLimiting": {
    "BookingEndpoint": {
      "Capacity": 50,      // Burst capacity
      "RefillRate": 10     // 10 requests per second sustained
    }
  }
}
```

### Comparison with Other Algorithms

| Algorithm | Pros | Cons | Use Case |
|-----------|------|------|----------|
| **Token Bucket** | Allows bursts, smooth refill | Complex implementation | General API rate limiting |
| **Leaky Bucket** | Constant output rate | No bursts allowed | Stream processing |
| **Fixed Window** | Simple | Burst at window boundaries | Simple rate limits |
| **Sliding Window** | Accurate, no boundary issues | More memory | Precise rate limiting |

### Performance Impact

**Test Scenario**: 1000 requests in 1 second

```csharp
// Token Bucket (50 capacity, 10/sec refill)
Result:
- First 50 requests: Immediate (burst capacity)
- Next 10 requests: 1 second later (refill)
- Next 10 requests: 2 seconds later
- ...
- Total time: ~95 seconds for 1000 requests
- Rejections: 0 (all queued and processed)
```

**Without Rate Limiting**:
```
Result: Service overwhelmed, crashes
Rejections: All requests after crash
```

**Code Location**: `/docs/phase4-gateway-security/RATE_LIMITING_IMPLEMENTATION.md`

---

## üîç Binary Search (Database Indexing)

### Problem

Find booking by ID in database with 1 million records.

### Algorithm

```
Sorted array: [2, 5, 8, 12, 16, 23, 38, 44, 56, 89]
Search for: 23

Step 1: Check middle (16) ‚Üí 23 > 16, search right half
Step 2: Check middle (44) ‚Üí 23 < 44, search left half
Step 3: Check middle (23) ‚Üí Found!

Complexity: O(log n)
```

### In Database Indexes (B-Tree)

```sql
-- Your BookingService database
CREATE INDEX idx_bookings_id ON bookings(id);
CREATE INDEX idx_bookings_userid ON bookings(user_id);

-- PostgreSQL uses B-Tree (generalized binary search tree)
```

**B-Tree Structure**:
```
Level 0 (Root):    [50, 100, 150]
                   /    |    |    \
Level 1:    [25,40] [75,90] [125,140] [175,190]
            /  |  \   ...
Level 2: [10] [30] [45] ...
```

### Query Performance

```csharp
// Without index: O(n) - Table scan
public async Task<Booking?> GetBookingByIdSlow(Guid id)
{
    // Scans all 1,000,000 bookings
    return await _dbContext.Bookings
        .FirstOrDefaultAsync(b => b.Id == id);
    // Time: ~1000ms
}

// With index: O(log n) - Index seek
public async Task<Booking?> GetBookingByIdFast(Guid id)
{
    // Uses index, binary search
    return await _dbContext.Bookings.FindAsync(id);
    // Time: ~1ms (1000x faster!)
}
```

### Real Performance Data

| Records | Linear Scan (O(n)) | Binary Search (O(log n)) | Speedup |
|---------|-------------------|-------------------------|---------|
| 1,000 | 1ms | 0.01ms | 100x |
| 10,000 | 10ms | 0.013ms | 770x |
| 100,000 | 100ms | 0.017ms | 5,880x |
| 1,000,000 | 1000ms | 0.020ms | 50,000x |

### When to Add Indexes

```csharp
// ‚úÖ Good: Index on foreign key
public class Booking
{
    public Guid UserId { get; set; } // ‚Üê Often queried
}

// Add index:
// CREATE INDEX idx_bookings_userid ON bookings(user_id);

// ‚úÖ Good: Composite index for common query
// Query: Find bookings by user and status
// CREATE INDEX idx_bookings_user_status 
//   ON bookings(user_id, status);

// ‚ùå Bad: Index on every column (wastes space, slows inserts)
// ‚ùå Bad: Index on columns never queried
```

---

## üîÄ Consistent Hashing (Load Balancing)

### Problem

Distribute requests across multiple service instances. Need to:
- Balance load evenly
- Minimize disruption when instances added/removed

### Algorithm

```
Hash space: 0 to 2^32-1 (ring)

1. Hash each server: hash(server1), hash(server2), ...
2. Place servers on ring
3. For request, hash key: hash(userId)
4. Walk clockwise to find next server
5. Route request to that server
```

### Visual Representation

```
Hash Ring:
         0
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ
   S3         S1
    ‚îÇ         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        S2

Request for user123:
hash(user123) = 150 ‚Üí Clockwise ‚Üí Server 1
hash(user456) = 300 ‚Üí Clockwise ‚Üí Server 2
```

### Implementation

```csharp
public class ConsistentHashRing
{
    private readonly SortedDictionary<int, string> _ring = new();
    private readonly int _virtualNodes = 150; // More = better distribution
    
    public void AddServer(string server)
    {
        // Add virtual nodes for better distribution
        for (int i = 0; i < _virtualNodes; i++)
        {
            var hash = GetHash($"{server}:{i}");
            _ring[hash] = server;
        }
    }
    
    public void RemoveServer(string server)
    {
        for (int i = 0; i < _virtualNodes; i++)
        {
            var hash = GetHash($"{server}:{i}");
            _ring.Remove(hash);
        }
    }
    
    public string GetServer(string key)
    {
        if (_ring.Count == 0)
            throw new InvalidOperationException("No servers available");
        
        var hash = GetHash(key);
        
        // Find first server clockwise from hash
        foreach (var kvp in _ring)
        {
            if (kvp.Key >= hash)
                return kvp.Value;
        }
        
        // Wrap around to first server
        return _ring.First().Value;
    }
    
    private int GetHash(string key)
    {
        using var md5 = MD5.Create();
        var hashBytes = md5.ComputeHash(Encoding.UTF8.GetBytes(key));
        return BitConverter.ToInt32(hashBytes, 0);
    }
}
```

### Why Better Than Modulo

**Modulo Hashing**:
```
3 servers: route = hash(key) % 3

Add 1 server ‚Üí route = hash(key) % 4
Result: 75% of keys reassigned! (cache misses)
```

**Consistent Hashing**:
```
3 servers on ring

Add 1 server ‚Üí Only ~25% of keys reassigned
Result: 75% of cache still valid!
```

### Application in Your Project

```csharp
// Cache server selection for user sessions
public class SessionCache
{
    private readonly ConsistentHashRing _ring = new();
    
    public SessionCache()
    {
        _ring.AddServer("cache-1");
        _ring.AddServer("cache-2");
        _ring.AddServer("cache-3");
    }
    
    public string GetCacheServer(string userId)
    {
        // Same user always routes to same cache server
        return _ring.GetServer(userId);
    }
    
    public async Task<User?> GetUserAsync(string userId)
    {
        var server = GetCacheServer(userId);
        return await _cacheClients[server].GetAsync<User>(userId);
    }
}
```

---

## üìä Sliding Window (Rate Limiting & Monitoring)

### Problem

Count requests in last N seconds (for rate limiting or metrics).

### Algorithm

```
Window: Last 60 seconds
Requests: [t-58s, t-45s, t-30s, t-10s, t-2s, t-1s]

At time t:
1. Remove requests older than (t - 60s)
2. Count remaining requests
3. If count < limit: Allow
4. If count ‚â• limit: Deny
```

### Implementation

```csharp
public class SlidingWindowRateLimiter
{
    private readonly Queue<DateTime> _requestTimestamps = new();
    private readonly int _windowSeconds;
    private readonly int _maxRequests;
    private readonly SemaphoreSlim _lock = new(1, 1);
    
    public SlidingWindowRateLimiter(int windowSeconds, int maxRequests)
    {
        _windowSeconds = windowSeconds;
        _maxRequests = maxRequests;
    }
    
    public async Task<bool> AllowRequestAsync()
    {
        await _lock.WaitAsync();
        try
        {
            var now = DateTime.UtcNow;
            var windowStart = now.AddSeconds(-_windowSeconds);
            
            // 1. Remove expired requests (dequeue from front)
            while (_requestTimestamps.Count > 0 
                   && _requestTimestamps.Peek() < windowStart)
            {
                _requestTimestamps.Dequeue();
            }
            
            // 2. Check limit
            if (_requestTimestamps.Count < _maxRequests)
            {
                // 3. Add new request (enqueue at rear)
                _requestTimestamps.Enqueue(now);
                return true;
            }
            
            return false;
        }
        finally
        {
            _lock.Release();
        }
    }
}
```

### Comparison: Fixed Window vs Sliding Window

**Fixed Window** (0-60s, 61-120s, ...):
```
Time:   [---- Window 1: 0-60s ----][---- Window 2: 61-120s ----]
Limit:  100 requests per window

Problem at boundary:
59s: 100 requests (allowed)
61s: 100 requests (allowed)
Total in 2 seconds: 200 requests! (burst)
```

**Sliding Window**:
```
Any 60-second period: Max 100 requests
No boundary problem
More accurate rate limiting
```

### Space Complexity

```
Fixed Window: O(1) - Just store counter
Sliding Window: O(n) - Store all timestamps

Trade-off:
- Fixed: Less memory, less accurate
- Sliding: More memory, more accurate

Optimization: Use buckets
Instead of storing each timestamp,
store count per second: O(window_size)
```

---

## üéØ Topological Sort (Service Startup Order)

### Problem

Services have dependencies. Need correct startup order.

### Algorithm (Kahn's Algorithm)

```
1. Find all nodes with no incoming edges (no dependencies)
2. Add to queue
3. While queue not empty:
   a. Remove node from queue
   b. Add to result
   c. Remove outgoing edges
   d. If any node now has no incoming edges, add to queue
4. If result contains all nodes: Success
   If not: Circular dependency detected
```

### Implementation

```csharp
public class ServiceDependencyResolver
{
    private readonly Dictionary<string, List<string>> _dependencies = new()
    {
        ["APIGateway"] = new() { "UserService", "BookingService", "PaymentService" },
        ["UserService"] = new() { "PostgreSQL-Users" },
        ["BookingService"] = new() { "PostgreSQL-Bookings", "RabbitMQ" },
        ["PaymentService"] = new() { "MongoDB", "RabbitMQ" },
        ["RabbitMQ"] = new() { },
        ["PostgreSQL-Users"] = new() { },
        ["PostgreSQL-Bookings"] = new() { },
        ["MongoDB"] = new() { }
    };
    
    public List<string> GetStartupOrder()
    {
        // Build adjacency list and in-degree count
        var inDegree = new Dictionary<string, int>();
        var adjList = new Dictionary<string, List<string>>();
        
        foreach (var service in _dependencies.Keys)
        {
            inDegree[service] = 0;
            adjList[service] = new List<string>();
        }
        
        // Count dependencies (in-degree)
        foreach (var (service, dependencies) in _dependencies)
        {
            foreach (var dependency in dependencies)
            {
                adjList[dependency].Add(service);
                inDegree[service]++;
            }
        }
        
        // Queue of services with no dependencies
        var queue = new Queue<string>();
        foreach (var (service, degree) in inDegree)
        {
            if (degree == 0)
                queue.Enqueue(service);
        }
        
        // Process in topological order
        var startupOrder = new List<string>();
        
        while (queue.Count > 0)
        {
            var service = queue.Dequeue();
            startupOrder.Add(service);
            
            // Remove this service's edges
            foreach (var dependent in adjList[service])
            {
                inDegree[dependent]--;
                if (inDegree[dependent] == 0)
                {
                    queue.Enqueue(dependent);
                }
            }
        }
        
        // Check for circular dependencies
        if (startupOrder.Count != _dependencies.Count)
        {
            throw new InvalidOperationException(
                "Circular dependency detected!"
            );
        }
        
        return startupOrder;
    }
}
```

### Result

```
Startup Order:
1. RabbitMQ
2. PostgreSQL-Users
3. PostgreSQL-Bookings
4. MongoDB
5. UserService
6. BookingService (depends on PostgreSQL-Bookings + RabbitMQ)
7. PaymentService (depends on MongoDB + RabbitMQ)
8. APIGateway (depends on all services)
```

### Application

```bash
# docker-compose.yml uses depends_on
services:
  apigateway:
    depends_on:
      - userservice
      - bookingservice
      - paymentservice
  
  bookingservice:
    depends_on:
      - bookingdb
      - rabbitmq
```

---

## üéì Key Takeaways

### Algorithm Complexity Reference

| Algorithm | Best Case | Average Case | Worst Case | Space |
|-----------|-----------|--------------|------------|-------|
| Exponential Backoff | O(1) | O(log n) | O(log n) | O(1) |
| Token Bucket | O(1) | O(1) | O(1) | O(1) |
| Binary Search | O(1) | O(log n) | O(log n) | O(1) |
| Consistent Hashing | O(log n) | O(log n) | O(log n) | O(n¬∑k) |
| Sliding Window | O(1) | O(n) | O(n) | O(n) |
| Topological Sort | O(V+E) | O(V+E) | O(V+E) | O(V) |

### When to Use Each

| Algorithm | Problem | Your Project Example |
|-----------|---------|---------------------|
| Exponential Backoff | Retry transient failures | RabbitMQ connection retry, event publishing |
| Token Bucket | Rate limiting with bursts | API Gateway rate limiting |
| Binary Search | Fast lookup in sorted data | Database indexes |
| Consistent Hashing | Distribute load evenly | Cache server selection, service routing |
| Sliding Window | Count in time window | Rate limiting, metrics |
| Topological Sort | Dependency ordering | Service startup, build order |

### Performance Impact in Your Project

**Without proper algorithms**:
- ‚ùå Thundering herd crashes RabbitMQ
- ‚ùå API overwhelmed, service crashes
- ‚ùå Slow database queries (1000ms)
- ‚ùå Uneven load distribution
- ‚ùå Wrong startup order, services fail

**With proper algorithms**:
- ‚úÖ Smooth retries with exponential backoff
- ‚úÖ API protected by token bucket
- ‚úÖ Fast queries with binary search indexes (1ms)
- ‚úÖ Even distribution with consistent hashing
- ‚úÖ Correct startup order with topological sort

---

## üìö Further Study

### Practice Problems
- **LeetCode**: #146 LRU Cache, #155 Min Stack, #207 Course Schedule
- **System Design**: Implement rate limiter, design cache, load balancer

### Related Documents
- [Data Structures](./data-structures-for-microservices.md)
- [Distributed Systems Theory](./distributed-systems-theory.md)
- [Rate Limiting Implementation](/docs/phase4-gateway-security/RATE_LIMITING_IMPLEMENTATION.md)

---

**Last Updated**: November 7, 2025  
**Next**: [Networking Fundamentals](./networking-fundamentals.md)
